# Ca1pherManus å¿«é€Ÿå¼€å§‹æŒ‡å—

## ğŸš€ 5åˆ†é’Ÿå¿«é€Ÿå¯åŠ¨

### 1. ç¯å¢ƒå‡†å¤‡

ç¡®ä¿ä½ çš„ç³»ç»Ÿå·²å®‰è£…ï¼š
- Python 3.8+
- Git

### 2. å…‹éš†é¡¹ç›®

```bash
git clone <repository-url>
cd Ca1pherManus
```

### 3. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ

```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv .venv

# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
# Windows
.venv\Scripts\activate
# Linux/Mac
source .venv/bin/activate
```

### 4. å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

### 5. é…ç½®ç¯å¢ƒå˜é‡

åˆ›å»º `.env` æ–‡ä»¶ï¼š

```bash
# å¤åˆ¶ç¯å¢ƒå˜é‡æ¨¡æ¿
cp .env.example .env

# ç¼–è¾‘ .env æ–‡ä»¶ï¼Œæ·»åŠ ä½ çš„ OpenAI API Key
OPENAI_API_KEY=your_openai_api_key_here
```

### 6. å¯åŠ¨æœåŠ¡

```bash
python -m uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

### 7. æµ‹è¯•æœåŠ¡

æ‰“å¼€æµè§ˆå™¨è®¿é—®ï¼šhttp://localhost:8000/docs

æˆ–è€…ä½¿ç”¨ curl æµ‹è¯•ï¼š

```bash
curl -X POST "http://localhost:8000/api/v1/chat" \
  -H "Content-Type: application/json" \
  -d '{"message": "æˆ‘æƒ³ä¸‹è½½å®‰è£…whistle"}'
```

## ğŸ“– ä½¿ç”¨ç¤ºä¾‹

### åŸºç¡€èŠå¤©

```python
import requests

# å‘é€èŠå¤©è¯·æ±‚
response = requests.post(
    "http://localhost:8000/api/v1/chat",
    json={"message": "æˆ‘æƒ³ä¸‹è½½å®‰è£…whistle"}
)

print(response.json())
```

### æµå¼èŠå¤©

```python
import requests

# æµå¼èŠå¤©è¯·æ±‚
response = requests.post(
    "http://localhost:8000/api/v1/chat/stream",
    json={"message": "æˆ‘æƒ³ä¸‹è½½å®‰è£…whistle"},
    stream=True
)

for chunk in response.iter_content(chunk_size=1024):
    if chunk:
        print(chunk.decode(), end='')
```

### JavaScript å‰ç«¯ç¤ºä¾‹

```javascript
// åŸºç¡€èŠå¤©
async function chat(message) {
    const response = await fetch('http://localhost:8000/api/v1/chat', {
        method: 'POST',
        headers: {
            'Content-Type': 'application/json',
        },
        body: JSON.stringify({ message })
    });
    
    const data = await response.json();
    return data.response;
}

// æµå¼èŠå¤©
async function chatStream(message, onChunk) {
    const response = await fetch('http://localhost:8000/api/v1/chat/stream', {
        method: 'POST',
        headers: {
            'Content-Type': 'application/json',
        },
        body: JSON.stringify({ message })
    });
    
    const reader = response.body.getReader();
    const decoder = new TextDecoder();
    
    while (true) {
        const { done, value } = await reader.read();
        if (done) break;
        
        const chunk = decoder.decode(value);
        const lines = chunk.split('\n');
        
        for (const line of lines) {
            if (line.startsWith('data: ')) {
                const data = JSON.parse(line.slice(6));
                onChunk(data);
            }
        }
    }
}

// ä½¿ç”¨ç¤ºä¾‹
chatStream("æˆ‘æƒ³ä¸‹è½½å®‰è£…whistle", (data) => {
    console.log(data);
});
```

## ğŸ”§ é…ç½®è¯´æ˜

### å·¥äººé…ç½®

ç¼–è¾‘ `app/langgraph_core/agents/workers_config.yaml`ï¼š

```yaml
workers:
  - name: other_worker
    handler_function: "app.langgraph_core.agents.main.other_worker_agent.other_worker_node"
    tools: []
```

### LLM é…ç½®

ç¼–è¾‘ `app/llms/reasoning_models.py`ï¼š

```python
# Supervisor LLM
supervisor_llm = ChatOpenAI(
    model="gpt-4o-mini", 
    temperature=0.6
)

# Planner LLM
planner_llm = ChatOpenAI(
    model="gpt-4o-mini", 
    temperature=0.3
)

# Worker LLM
worker_llm = ChatOpenAI(
    model="gpt-4o-mini", 
    temperature=0.7
)
```

## ğŸ› å¸¸è§é—®é¢˜

### 1. å¯åŠ¨å¤±è´¥

**é—®é¢˜**ï¼š`ModuleNotFoundError: No module named 'app'`

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# ç¡®ä¿åœ¨é¡¹ç›®æ ¹ç›®å½•
pwd
# åº”è¯¥æ˜¾ç¤º /path/to/Ca1pherManus

# æ£€æŸ¥ Python è·¯å¾„
python -c "import sys; print(sys.path)"

# é‡æ–°å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

### 2. API Key é”™è¯¯

**é—®é¢˜**ï¼š`openai.AuthenticationError: Invalid API key`

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# æ£€æŸ¥ç¯å¢ƒå˜é‡
echo $OPENAI_API_KEY

# æˆ–è€…åœ¨ Windows ä¸Š
echo %OPENAI_API_KEY%

# é‡æ–°è®¾ç½®ç¯å¢ƒå˜é‡
export OPENAI_API_KEY=your_api_key_here
```

### 3. ç«¯å£è¢«å ç”¨

**é—®é¢˜**ï¼š`OSError: [Errno 98] Address already in use`

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# æŸ¥æ‰¾å ç”¨ç«¯å£çš„è¿›ç¨‹
lsof -i :8000

# æ€æ­»è¿›ç¨‹
kill -9 <PID>

# æˆ–è€…ä½¿ç”¨å…¶ä»–ç«¯å£
python -m uvicorn app.main:app --reload --host 0.0.0.0 --port 8001
```

### 4. ä¾èµ–å®‰è£…å¤±è´¥

**é—®é¢˜**ï¼š`pip install` å¤±è´¥

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# å‡çº§ pip
pip install --upgrade pip

# æ¸…ç†ç¼“å­˜
pip cache purge

# é‡æ–°å®‰è£…
pip install -r requirements.txt --no-cache-dir
```

## ğŸ“Š ç›‘æ§å’Œæ—¥å¿—

### æŸ¥çœ‹æ—¥å¿—

```bash
# æŸ¥çœ‹åº”ç”¨æ—¥å¿—
tail -f logs/app.log

# æŸ¥çœ‹é”™è¯¯æ—¥å¿—
tail -f logs/error.log
```

### å¥åº·æ£€æŸ¥

```bash
# æ£€æŸ¥æœåŠ¡çŠ¶æ€
curl http://localhost:8000/health

# æ£€æŸ¥ API æ–‡æ¡£
curl http://localhost:8000/docs
```

## ğŸ” è°ƒè¯•æŠ€å·§

### 1. å¯ç”¨è°ƒè¯•æ¨¡å¼

```bash
# è®¾ç½®è°ƒè¯•ç¯å¢ƒå˜é‡
export DEBUG=1
export LOG_LEVEL=DEBUG

# å¯åŠ¨æœåŠ¡
python -m uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

### 2. æŸ¥çœ‹è¯¦ç»†æ—¥å¿—

```python
import logging

# è®¾ç½®æ—¥å¿—çº§åˆ«
logging.basicConfig(level=logging.DEBUG)

# åœ¨ä»£ç ä¸­æ·»åŠ æ—¥å¿—
logger = logging.getLogger(__name__)
logger.debug("è°ƒè¯•ä¿¡æ¯")
logger.info("ä¸€èˆ¬ä¿¡æ¯")
logger.error("é”™è¯¯ä¿¡æ¯")
```

### 3. çŠ¶æ€è°ƒè¯•

```python
# åœ¨ä»£ç†ä¸­æ·»åŠ çŠ¶æ€è°ƒè¯•
def debug_state(state):
    print("=== çŠ¶æ€è°ƒè¯• ===")
    print(f"å½“å‰ä»£ç†: {state.get('current_agent_role')}")
    print(f"å½“å‰è¯·æ±‚: {state.get('current_request')}")
    print(f"è®¡åˆ’æ­¥éª¤: {len(state.get('overall_plan', {}).get('steps', []))}")
    print("===============")
```

## ğŸš€ æ€§èƒ½ä¼˜åŒ–

### 1. ç¼“å­˜é…ç½®

```python
# å¯ç”¨ç¼“å­˜
from functools import lru_cache

@lru_cache(maxsize=128)
def cached_function(input_data):
    return expensive_operation(input_data)
```

### 2. å¼‚æ­¥å¤„ç†

```python
import asyncio

async def async_operation():
    # å¼‚æ­¥æ“ä½œ
    result = await some_async_function()
    return result
```

### 3. å†…å­˜ä¼˜åŒ–

```python
# æ¸…ç†çŠ¶æ€
def cleanup_state(state):
    # æ¸…ç†è¿‡é•¿çš„æ¶ˆæ¯å†å²
    if len(state.get("messages", [])) > 100:
        state["messages"] = state["messages"][-50:]
    return state
```

## ğŸ“š å­¦ä¹ èµ„æº

### 1. å®˜æ–¹æ–‡æ¡£
- [FastAPI æ–‡æ¡£](https://fastapi.tiangolo.com/)
- [LangGraph æ–‡æ¡£](https://langchain-ai.github.io/langgraph/)
- [LangChain æ–‡æ¡£](https://python.langchain.com/)

### 2. é¡¹ç›®æ–‡æ¡£
- [æŠ€æœ¯æ¶æ„æ–‡æ¡£](docs/TECHNICAL_ARCHITECTURE.md)
- [å¼€å‘æŒ‡å—](docs/DEVELOPMENT_GUIDE.md)
- [é¡¹ç›®çŠ¶æ€](docs/PROJECT_STATUS.md)

### 3. ç¤ºä¾‹ä»£ç 
- [æµ‹è¯•æ–‡ä»¶](test/)
- [API ç¤ºä¾‹](test_main.http)

## ğŸ¤ è·å–å¸®åŠ©

### 1. æŸ¥çœ‹æ—¥å¿—
```bash
tail -f logs/app.log
```

### 2. æ£€æŸ¥çŠ¶æ€
```bash
# æ£€æŸ¥æœåŠ¡çŠ¶æ€
curl http://localhost:8000/health

# æ£€æŸ¥é…ç½®
python -c "from app.core.config import settings; print(settings.dict())"
```

### 3. è”ç³»æ”¯æŒ
- åˆ›å»º Issue
- æŸ¥çœ‹æ–‡æ¡£
- åŠ å…¥ç¤¾åŒº

---

**å¼€å§‹ä½ çš„ Ca1pherManus ä¹‹æ—…ï¼** ğŸš€

å¦‚æœ‰é—®é¢˜ï¼Œè¯·æŸ¥çœ‹ [é¡¹ç›®çŠ¶æ€æ–‡æ¡£](docs/PROJECT_STATUS.md) æˆ–åˆ›å»º Issueã€‚ 